---
title: "Extending Implicit Neural Representations for Text-to-Image Generation"
collection: publications
permalink: /publication/ExtendingImplicitNeuralRepresentations-1
excerpt: '**Guanming Liu**, Zhihua Wei, et al'
date: 2024-3-15
venue: 'ICASSP'
# paperurl: 'http://academicpages.github.io/files/paper1.pdf'
# citation: 'Your Name, You. (2009). &quot;Paper Title Number 1.&quot; <i>Journal 1</i>. 1(1).'
# Description
# [Description] It explores the relationship between the frequency domain representation of continuous image signals and the discrete textual features using the CLIP model. Specifically, we employ the StyleGAN architecture and introduce innovative techniques such as frequency modulation and cross-attention modulation to incorporate the features of sentences and words. As an INR-based GAN, our model exhibits characteristics such as extrapolation beyond image boundaries and arbitrary image resolution generation.
---
<!-- This paper is about the number 1. The number 2 is left for future work. -->

<!-- [Download paper here](http://academicpages.github.io/files/paper1.pdf) -->

<!-- Recommended citation: Your Name, You. (2009). "Paper Title Number 1." <i>Journal 1</i>. 1(1). -->
